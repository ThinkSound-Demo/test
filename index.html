<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
    <title>ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation</title>
    <style>
    @import url('https://fonts.googleapis.com/css2?family=Quicksand:wght@400;600&display=swap');

    body {
        font-family: 'Quicksand', sans-serif;
        text-align: center;
        padding: 0 20px 40px 20px;
        background: linear-gradient(135deg, #c6c7c9, #fbfbfc);
        width: 800px;
        margin: 40px auto;
        color: #344055;
        user-select: none;
        -webkit-font-smoothing: antialiased;
    }

    h1 {
        margin-bottom: 50px;
        color: #2a3a4b;
        font-weight: 700;
        font-size: 2.8rem;
        letter-spacing: 0.08em;
        text-shadow: 0 1px 3px rgba(50, 80, 130, 0.15);
    }

    h2, .chapter-title {
        font-size: 1.4rem;
        text-align: left;
        margin-bottom: 12px;
        color: #636363;
        border-left: 6px solid #acb5c1;
        padding-left: 12px;
        font-weight: 600;
        letter-spacing: 0.03em;
    }

    hr, .chapter-line {
        border: none;
        border-top: 2px solid #bdd7ee;
        margin: 6px 0 20px 0;
        text-align: left;
        width: 100%;
        max-width: 980px;
    }

    #video-selector {
        width: 100%;
        max-width: 900px;
        margin: 30px auto 60px auto;
        display: flex;
        flex-direction: column;
        gap: 60px;
    }

    .section {
        background-color: #f0f7ff;
        padding: 28px 32px;
        border-radius: 14px;
        box-shadow: 0 8px 14px rgba(159, 183, 226, 0.3);
        margin-bottom: 60px;
        transition: box-shadow 0.3s ease;
    }

    .section:hover {
        box-shadow: 0 12px 20px rgba(115, 154, 228, 0.45);
    }

    .section-title {
        font-size: 2rem;
        color: #24446e;
        margin-bottom: 26px;
        font-weight: 700;
    }

    .video-row {
        display: flex;
        justify-content: space-between;
        flex-wrap: wrap;
        gap: 20px;
    }

    .video-column {
        width: 23%;
        margin-bottom: 20px;
        display: flex;
        flex-direction: column;
        align-items: center;
        background: #ffffffcc;
        border-radius: 12px;
        box-shadow: 0 4px 8px rgba(180, 200, 230, 0.3);
        padding: 10px;
        transition: box-shadow 0.3s ease;
    }

    .video-column:hover {
        box-shadow: 0 8px 14px rgba(120, 160, 210, 0.5);
    }

    .video-player-container {
        width: 100%;
        height: 190px;
        position: relative;
        background-color: #dde8fc;
        border-radius: 10px;
        overflow: hidden;
        box-shadow: inset 0 0 15px rgba(180, 200, 230, 0.7);
    }

    .video-player-container iframe, 
    .video-player-container video {
        width: 100%;
        height: 100%;
        border: none;
        border-radius: 10px;
    }

    .fullscreen-btn {
        position: absolute;
        top: 10px;
        right: 10px;
        background-color: rgba(255, 255, 255, 0.85);
        color: #4466aa;
        border: 1px solid #a3c4f3;
        padding: 6px 12px;
        cursor: pointer;
        border-radius: 8px;
        font-weight: 600;
        font-size: 0.9rem;
        transition: background-color 0.3s ease;
    }

    .fullscreen-btn:hover {
        background-color: #a3c4f3;
        color: #fff;
        border-color: #557a95;
    }

    .caption {
        font-size: 1.3rem;
        color: #2e4661;
        margin-top: 18px;
        margin-bottom: 20px;
        font-weight: 700;
        letter-spacing: 0.04em;
    }

    .video-title {
        font-size: 1rem;
        color: #557a95;
        margin-top: 18px;
        font-weight: 500;
        letter-spacing: 0.02em;
    }

    .image-container {
        margin: 40px auto;
        text-align: center;
        max-width: 960px;
    }

    .image-caption {
        font-size: 1rem;
        color: #5b738d;
        margin-top: 12px;
        font-style: italic;
        letter-spacing: 0.02em;
    }

    table {
        width: 100%;
        border-collapse: collapse;
        margin-bottom: 40px;
        box-shadow: 0 4px 8px rgba(120, 140, 180, 0.2);
        background-color: #f7fbff;
        border-radius: 10px;
        overflow: hidden;
    }

    caption {
        font-style: italic;
        text-align: center;
        caption-side: bottom;
        margin-top: 12px;
        color: #557a95;
        font-weight: 600;
    }

    th, td {
        padding: 14px 12px;
        text-align: center;
        border-bottom: 1px solid #d3def3;
        color: #344055;
    }

    th {
        background-color: #dbe9ff;
        font-weight: 700;
        letter-spacing: 0.04em;
    }

    .button-container {
        display: flex;
        flex-wrap: wrap;
        justify-content: space-between;
    }

    .button-container .fold-btn {
        flex: 0 0 23%;
        margin-bottom: 12px;
        background: #a7c3ff66;
        border-radius: 8px;
        border: 1px solid #8ea7d4;
        color: #35508a;
        font-weight: 600;
        cursor: pointer;
        padding: 8px 0;
        transition: background-color 0.3s ease;
    }

    .button-container .fold-btn:hover {
        background: #aac7ffaa;
    }

    #prevBtn, #nextBtn {
        background-color: #a7c3ffcc;
        border: 1px solid #7b9de0;
        padding: 10px 16px;
        font-size: 22px;
        color: #24446e;
        border-radius: 10px;
        cursor: pointer;
        user-select: none;
        transition: background-color 0.3s ease;
        box-shadow: 0 4px 6px rgba(115, 150, 230, 0.5);
    }

    #prevBtn:hover, #nextBtn:hover {
        background-color: #7eabffdd;
        color: #1b2c4e;
    }

    /* Scrollbar for carousel */
    #carousel::-webkit-scrollbar {
        height: 8px;
    }

    #carousel::-webkit-scrollbar-track {
        background: #e0efff;
        border-radius: 8px;
    }

    #carousel::-webkit-scrollbar-thumb {
        background: #a3c4f3;
        border-radius: 8px;
    }



    /* Èº†Ê†áÊãñÂä®Êó∂ÁöÑÊ†∑Âºè */
    #carousel.dragging {
        cursor: grabbing;
        scroll-behavior: auto;
    }



    /* ‰ΩøÊí≠ÊîæÊó∂Â±Ö‰∏≠Êõ¥Ëá™ÁÑ∂ */
    #carousel-container {
        overflow: hidden;
        width: 100%;
        scroll-snap-type: x mandatory;
        padding-bottom: 10px;
    }
    #carousel-container {
        position: relative;
        width: 100%;
        overflow: hidden;
    }

    /* Ë∞ÉÊï¥ÂêéÁöÑcarouselÊ†∑Âºè */
    #carousel {
        display: flex;
        scroll-behavior: smooth;
        padding: 20px 50%; /* ÂàõÂª∫Â∑¶Âè≥ÂèØËßÅÂå∫Âüü */
        margin-left: -180px; /* Ë°•ÂÅøÂàùÂßãÂÅèÁßª */
    }

    .video-card {
        flex: 0 0 360px;  /* Âõ∫ÂÆöÂÆΩÂ∫¶ */
        height: 240px;    /* Âõ∫ÂÆöÈ´òÂ∫¶ */
        margin: 0 10px;
        overflow: hidden; /* ÈöêËóèÊ∫¢Âá∫ÂÜÖÂÆπ */
        position: relative;
        border-radius: 10px; /* Ê∑ªÂä†ÂúÜËßí */
        overflow: hidden;     /* ÈöêËóèÊ∫¢Âá∫ÂÜÖÂÆπ */
        border: 5px solid rgba(68, 102, 170, 0.3);
        transition: all 0.25s cubic-bezier(0.34, 1.56, 0.64, 1);
    }

    /* ‰øÆÊîπËßÜÈ¢ëÂÖÉÁ¥†Ê†∑Âºè */
    .video-card video {
        width: 100%;
        height: 100%;
        object-fit: cover; /* ‰øùÊåÅÊØî‰æãÂ°´ÂÖÖÂÆπÂô® */
        object-position: center;
    }

    /* Êñ∞Â¢ûÂÖãÈöÜËßÜÈ¢ëÊ†∑Âºè */
    .clone-card {
        opacity: 0.5;
        transform: scale(0.9);
    }

    .ablation-table {
    width: 100%;
    border-collapse: collapse;
    margin-top: 10px;
    font-size: 14px;
    }

    .ablation-table th, .ablation-table td {
    border: 1px solid #ccc;
    padding: 6px 10px;
    text-align: center;
    }

    .ablation-table caption {
    caption-side: top;
    text-align: left;
    font-weight: bold;
    margin-bottom: 4px;
    }


</style>


</head>
<body>
    <h1>ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation</h1>

    <!-- Abstract section -->
    <div class="abstract" style="text-align: center;"></div>
        <h2 class="chapter-title">Abstract</h2>
        <hr class="chapter-line">
        <p style="text-align: left;"> While end-to-end video-to-audio generation has greatly improved, producing high-fidelity audio that authentically captures the nuances of visual content remains challenging. Like professionals in the creative industries, such generation requires sophisticated reasoning about items such as visual dynamics, acoustic environments, and temporal relationships. We present ThinkSound, a novel framework that leverages Chain-of-Thought (CoT) reasoning to enable stepwise, interactive audio generation and editing for videos. Our approach decomposes the process into three complementary stages: foundational foley generation that creates semantically coherent soundscapes, interactive object-centric refinement through precise user interactions, and targeted editing guided by natural language instructions. At each stage, a multimodal large language model generates contextually aligned CoT reasoning that guides a unified audio foundation model. Furthermore, we introduce \textbf{AudioCoT}, a comprehensive dataset with structured reasoning annotations that establishes connections between visual content, textual descriptions, and sound synthesis.  Experiments demonstrate that ThinkSound achieves state-of-the-art performance in video-to-audio generation across both audio metrics and CoT metrics and excels in out-of-distribution Movie Gen Audio benchmark.</p>
    </div>
    
    <div class="video-carousel-section" style="text-align: center;">
    <h2 class="chapter-title">Video Demo</h2>
    <hr class="chapter-line">
    <strong style="font-size: 19px; display: block; margin-bottom: 20px;">
        üéß Please wear headphones to experience the demo üé•.
    </strong>

    <div class="carousel-container" style="display: flex; justify-content: center; align-items: center; position: relative;">
        
        
        <div id="carousel" style="max-width: 700px; overflow: hidden ;margin: 0 auto;"></div>">
            <!-- Current video will be inserted here -->
        </div>

        
    </div>

    <div id="video-id" class="caption" style="margin-top: 10px; font-weight: bold;"></div>
</div>

<script>
const videoPaths = [
    "videos/video1.mp4",
    "videos/video2.mp4",
    "videos/video3.mp4"
];

const carousel = document.getElementById('carousel');

function createVideoCard(src, index) {
    const container = document.createElement('div');
    container.className = 'video-card';

    const video = document.createElement('video');
    video.src = src;
    video.controls = true;
    video.style.width = '100%';
    video.style.borderRadius = '10px';
    video.style.backgroundColor = '#000';

    video.addEventListener('play', () => {
        const left = container.offsetLeft - carousel.offsetWidth / 2 + container.offsetWidth / 2;
        carousel.scrollTo({ left, behavior: 'smooth' });
    });

    container.appendChild(video);
    return container;
}

videoPaths.forEach((src, i) => {
    carousel.appendChild(createVideoCard(src, i));
});

setTimeout(() => {
    const middleIndex = Math.floor(videoPaths.length / 2);
    const cardWidth = 600 + 20; 
    carousel.scrollLeft = cardWidth * middleIndex;
  const updateScales = () => {
    const containerCenter = carousel.scrollLeft + carousel.offsetWidth / 2;
    
    
    Array.from(carousel.children).forEach(card => {
      const cardCenter = card.offsetLeft + card.offsetWidth / 2;
      // ‰ΩøÁî®Áõ∏ÂØπ‰ΩçÁΩÆÊØî‰æãËÆ°ÁÆóÁº©ÊîæÂÄºÔºà-1Âà∞1‰πãÈó¥Ôºâ
      const positionRatio = (cardCenter - containerCenter) / (carousel.offsetWidth * 0.8);
      // ‰ΩøÁî®‰ΩôÂº¶Êõ≤Á∫øÂÆûÁé∞Âπ≥ÊªëËøáÊ∏°
      const scale = 0.9 + 0.3 * Math.cos(positionRatio * Math.PI);
      
      card.style.transform = `scale(${scale})`;
      card.style.opacity = 0.8 + 0.2 * (1 - Math.abs(positionRatio));
    });
    
    requestAnimationFrame(updateScales);
  };
  updateScales();
}, 100);

let isDragging = false;
let startX;
let scrollLeft;

carousel.addEventListener('mousemove', (e) => {
  if (!isDragging) return;
  e.preventDefault();
  
  // Ê∑ªÂä†ÊÉØÊÄßÁ≥ªÊï∞
  const inertia = 1.5 - Math.abs(carousel.scrollLeft - scrollLeft) / 1000;
  const x = e.pageX - carousel.offsetLeft;
  const walk = (x - startX) * 1.2 * Math.min(inertia, 1.2);
  
  carousel.scrollLeft = scrollLeft - walk;
});

carousel.addEventListener('mousedown', (e) => {
    isDragging = true;
    startX = e.pageX - carousel.offsetLeft;
    scrollLeft = carousel.scrollLeft;
    carousel.classList.add('dragging');
});

carousel.addEventListener('mouseleave', () => {
    isDragging = false;
    carousel.classList.remove('dragging');
});

carousel.addEventListener('mouseup', () => {
    isDragging = false;
    carousel.classList.remove('dragging');
});

carousel.addEventListener('mousemove', (e) => {
    if (!isDragging) return;
    e.preventDefault();
    const x = e.pageX - carousel.offsetLeft;
    const walk = (x - startX) * 1.2;
    carousel.scrollLeft = scrollLeft - walk;
});
</script>




    </script>
    <!-- Image section -->
    <div class="image-container">
        <h2 class="chapter-title">Samples</h2>
        <hr class="chapter-line">
        <p style="text-align: left; font-size: 16px; max-width: 96%; color: #333;">
            
        </p>
        <div class="button-container" style="margin-top: 20px; justify-content: center; gap: 16px;">
  <button class="sample-btn" data-set="set1">Sample Set 1</button>
  <button class="sample-btn" data-set="set2">Sample Set 2</button>
  <button class="sample-btn" data-set="set3">Sample Set 3</button>
</div>



<style>
  .sample-btn {
    background: #a3c4f3;
    border: none;
    border-radius: 10px;
    padding: 12px 24px;
    font-weight: 600;
    font-size: 1rem;
    color: #24446e;
    cursor: pointer;
    box-shadow: 0 4px 12px rgba(115, 150, 230, 0.4);
    transition: background-color 0.3s ease, color 0.3s ease;
    user-select: none;
  }
  .sample-btn:hover {
    background: #557a95;
    color: #f0f7ff;
  }
  .sample-btn.active {
    background: #24446e;
    color: #a3c4f3;
    box-shadow: inset 0 0 10px #557a95;
  }
  #video-row-container video {
    width: 220px;
    height: 130px;
    border-radius: 12px;
    box-shadow: 0 4px 12px rgba(90, 120, 160, 0.4);
    background-color: #000;
  }
</style>

<script>
  // Êú¨Âú∞ËßÜÈ¢ëË∑ØÂæÑÊò†Â∞ÑÁ§∫‰æãÔºåÈúÄÊõøÊç¢‰∏∫‰Ω†ÁöÑÂÆûÈôÖË∑ØÂæÑ
  const videoSets = {
    set1: {
      gt: { video: 'videos/set1/gt.mp4', audio: 'audios/set1/gt.mp3' },
      thinksound: { video: 'videos/set1/thinksound.mp4', audio: 'audios/set1/thinksound.mp3' },
      baseline1: { video: 'videos/set1/baseline1.mp4', audio: 'audios/set1/baseline1.mp3' },
      baseline2: { video: 'videos/set1/baseline2.mp4', audio: 'audios/set1/baseline2.mp3' },
    },
    set2: {
      gt: { video: 'videos/set2/gt.mp4', audio: 'audios/set2/gt.mp3' },
      thinksound: { video: 'videos/set2/thinksound.mp4', audio: 'audios/set2/thinksound.mp3' },
      baseline1: { video: 'videos/set2/baseline1.mp4', audio: 'audios/set2/baseline1.mp3' },
      baseline2: { video: 'videos/set2/baseline2.mp4', audio: 'audios/set2/baseline2.mp3' },
    },
    set3: {
      gt: { video: 'videos/set3/gt.mp4', audio: 'audios/set3/gt.mp3' },
      thinksound: { video: 'videos/set3/thinksound.mp4', audio: 'audios/set3/thinksound.mp3' },
      baseline1: { video: 'videos/set3/baseline1.mp4', audio: 'audios/set3/baseline1.mp3' },
      baseline2: { video: 'videos/set3/baseline2.mp4', audio: 'audios/set3/baseline2.mp3' },
    }
  };

  const btns = document.querySelectorAll('.sample-btn');
  const container = document.getElementById('video-row-container');

  // Âè™Êí≠ÊîæÂΩìÂâçÈÄâ‰∏≠ËßÜÈ¢ëÁöÑÈü≥È¢ë
  let currentAudioElements = [];

  btns.forEach(btn => {
    btn.addEventListener('click', () => {
      if (btn.classList.contains('active')) {
        // ÂèñÊ∂àÈÄâ‰∏≠
        btn.classList.remove('active');
        container.style.display = 'none';
        container.innerHTML = '';
        stopAllAudios();
        return;
      }
      // Ê∏ÖÈô§ÂÖ∂‰ªñÊåâÈíÆÊøÄÊ¥ªÁä∂ÊÄÅ
      btns.forEach(b => b.classList.remove('active'));
      btn.classList.add('active');

      const setName = btn.dataset.set;
      const videos = videoSets[setName];

      // Ê∏ÖÁ©∫ÊóßÂÜÖÂÆπÔºåÂÅúÊ≠¢ÊóßÈü≥È¢ë
      container.innerHTML = '';
      stopAllAudios();

      // ÂàõÂª∫ËßÜÈ¢ë+Èü≥È¢ëÊéß‰ª∂
      for (const [label, paths] of Object.entries(videos)) {
        const video = document.createElement('video');
        video.src = paths.video;
        video.controls = true;
        video.muted = true;  // ÈùôÈü≥ËßÜÈ¢ë
        video.setAttribute('playsinline', ''); // ÁßªÂä®Á´ØÂÖºÂÆπ
        video.style.width = '220px';
        video.style.height = '130px';
        video.style.borderRadius = '12px';
        video.style.boxShadow = '0 4px 12px rgba(90, 120, 160, 0.4)';
        video.style.backgroundColor = '#000';

        // ÂàõÂª∫Èü≥È¢ëÂÖÉÁ¥†
        const audio = document.createElement('audio');
        audio.src = paths.audio;
        audio.preload = 'auto';

        // ÂêåÊ≠•Êí≠ÊîæÈü≥È¢ëÂíåËßÜÈ¢ë
        video.addEventListener('play', () => {
          audio.currentTime = video.currentTime;
          audio.play();
        });
        video.addEventListener('pause', () => {
          audio.pause();
        });
        video.addEventListener('seeking', () => {
          audio.currentTime = video.currentTime;
        });
        video.addEventListener('ended', () => {
          audio.pause();
          audio.currentTime = 0;
        });

        currentAudioElements.push(audio);

        // ÂåÖË£ÖËßÜÈ¢ëÂíåÊ†áÈ¢ò
        const wrapper = document.createElement('div');
        wrapper.style.display = 'flex';
        wrapper.style.flexDirection = 'column';
        wrapper.style.alignItems = 'center';
        wrapper.style.width = '220px';
        wrapper.style.marginBottom = '10px';

        const title = document.createElement('div');
        title.textContent = label.toUpperCase();
        title.style.color = '#24446e';
        title.style.fontWeight = '600';
        title.style.marginTop = '6px';
        title.style.fontSize = '1rem';

        wrapper.appendChild(video);
        wrapper.appendChild(title);

        container.appendChild(wrapper);
      }

      container.style.display = 'flex';
    });
  });

  function stopAllAudios() {
    currentAudioElements.forEach(audio => {
      audio.pause();
      audio.currentTime = 0;
    });
    currentAudioElements = [];
  }
</script>

        
    </div>

    <div class="image-container">
        <h2 class="chapter-title">Extract Audio</h2>
        <hr class="chapter-line">
        <p style="text-align: left; font-size: 16px; max-width: 96%; color: #333;">
            
        </p>
    </div>

    <div class="image-container">
        <h2 class="chapter-title">Audio Editing</h2>
        <hr class="chapter-line">
        <p style="text-align: left; font-size: 16px; max-width: 96%; color: #333;">
            
        </p>
    </div>
        
        




    </div>
        <h2 class="chapter-title"> Ablation Studies</h2>
        <hr class="chapter-line">
        <div class="ablation-section">
            <div style="text-align: left;">

                <p>To better understand the contribution of each component in <strong>ThinkSound</strong> and to validate the effectiveness of our design choices, we conduct comprehensive ablation studies on the VGGSound test set. We mainly focus on: (1) text encoding strategies and (2) multi-modal integration mechanisms. For more ablation and exploratory results, refer to Supplementary Materials D.</p>

                <h3>Text Encoding Strategies</h3>
                <p>We evaluate different text encoding strategies with or without CoT reasoning. The results are shown in Table 1. First, CoT reasoning substantially improves audio fidelity‚Äîfor example, FD improves from 39.84 to 37.65 when comparing CLIP-only to T5 with CoT. Second, integrating contrastive features from CLIP with contextual reasoning from T5 further improves performance, reducing both KL<sub>PaSST</sub> and KL<sub>PaNNs</sub>.</p>
            </div>
        <table class="ablation-table">
            <caption>Table 1: Comparison of text encoder fusion strategies (CLAP = CLAP<sub>CoT</sub>)</caption>
            <thead>
            <tr>
                <th>Method</th>
                <th>FD ‚Üì</th>
                <th>KL<sub>PaSST</sub> ‚Üì</th>
                <th>KL<sub>PaNNs</sub> ‚Üì</th>
                <th>DeSync ‚Üì</th>
                <th>CLAP ‚Üë</th>
            </tr>
            </thead>
            <tbody>
            <tr>
                <td>CLIP</td>
                <td>39.84</td>
                <td>1.59</td>
                <td>1.40</td>
                <td>0.48</td>
                <td>0.41</td>
            </tr>
            <tr>
                <td>T5 (CoT)</td>
                <td>37.65</td>
                <td>1.54</td>
                <td>1.35</td>
                <td>0.46</td>
                <td>0.44</td>
            </tr>
            <tr>
                <td><strong>CLIP + T5</strong></td>
                <td><strong>34.56</strong></td>
                <td><strong>1.52</strong></td>
                <td><strong>1.32</strong></td>
                <td><strong>0.46</strong></td>
                <td><strong>0.46</strong></td>
            </tr>
            </tbody>
        </table>
        <div style="text-align: left;">
            <h3>Multi-Modal Integration Mechanisms</h3>
            <p>We investigate different ways to integrate video and audio features before feeding them into the single-stream transformer. As shown in Table 2, element-wise addition of video and audio features performs better than audio-only input, especially in synchronization (DeSync reduced from 0.50 to 0.46). Moreover, the gated fusion mechanism outperforms both alternatives across all metrics.</p>
        </div>
        <table class="ablation-table">
            <caption>Table 2: Comparison of multi-modal integration mechanisms</caption>
            <thead>
            <tr>
                <th>Integration</th>
                <th>FD ‚Üì</th>
                <th>KL<sub>PaSST</sub> ‚Üì</th>
                <th>KL<sub>PaNNs</sub> ‚Üì</th>
                <th>DeSync ‚Üì</th>
                <th>CLAP ‚Üë</th>
            </tr>
            </thead>
            <tbody>
            <tr>
                <td>audio only</td>
                <td>37.13</td>
                <td>1.58</td>
                <td>1.37</td>
                <td>0.50</td>
                <td>0.43</td>
            </tr>
            <tr>
                <td>linear video</td>
                <td>38.96</td>
                <td>1.58</td>
                <td>1.38</td>
                <td>0.46</td>
                <td>0.45</td>
            </tr>
            <tr>
                <td><strong>gated video</strong></td>
                <td><strong>34.56</strong></td>
                <td><strong>1.52</strong></td>
                <td><strong>1.32</strong></td>
                <td><strong>0.46</strong></td>
                <td><strong>0.46</strong></td>
            </tr>
            </tbody>
        </table>

        </div>

        
    <h2 class="chapter-title"> Code and Dataset </h2>
        <hr class="chapter-line">
        <p style="text-align: left; font-size: 16px; max-width: 96%; color: #333;">
          The code and dataset will be released soon. 
        </p>


</body>
</html>
